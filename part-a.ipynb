{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c2689e",
   "metadata": {},
   "source": [
    "# Hangman Solver using Hidden Markov Models (HMM)\n",
    "\n",
    "## Part A: HMM Implementation & Validation\n",
    "\n",
    "This notebook implements a probabilistic approach to predict letters in Hangman using Hidden Markov Models with character sequence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aab8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from hmmlearn import hmm\n",
    "import string\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def load_corpus(file_path):\n",
    "    \"\"\"Load words from corpus file\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "    return words\n",
    "\n",
    "def preprocess_words(words):\n",
    "    \"\"\"Preprocess words: lowercase and filter\"\"\"\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word.isalpha():\n",
    "            processed_words.append(word)\n",
    "    return processed_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2a5ea",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Data Preprocessing\n",
    "\n",
    "**Algorithm:** Text Preprocessing with Filtering\n",
    "- Load corpus and test files\n",
    "- Normalize text (lowercase conversion)\n",
    "- Filter non-alphabetic words using basic string operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9614c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Total words in corpus: 50000\n",
      "✓ Words after preprocessing: 49979\n",
      "✓ Test words loaded: 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load training corpus\n",
    "corpus_path = 'Data/corpus.txt'\n",
    "raw_words = load_corpus(corpus_path)\n",
    "processed_words = preprocess_words(raw_words)\n",
    "\n",
    "print(f\"✓ Total words in corpus: {len(raw_words)}\")\n",
    "print(f\"✓ Words after preprocessing: {len(processed_words)}\")\n",
    "\n",
    "# Load test data\n",
    "test_path = 'Data/test.txt'\n",
    "test_words_raw = load_corpus(test_path)\n",
    "test_words = preprocess_words(test_words_raw)\n",
    "print(f\"✓ Test words loaded: {len(test_words)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1f808",
   "metadata": {},
   "source": [
    "## Step 2: Load Training & Test Data\n",
    "\n",
    "**Operation:** File I/O and Data Loading\n",
    "- Load corpus words for training HMM models\n",
    "- Load test set for validation\n",
    "- Display dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f9c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# HMM MODEL CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class HangmanHMM:\n",
    "    \"\"\"Hidden Markov Model for Hangman letter prediction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.alphabet = string.ascii_lowercase\n",
    "        self.letter_to_idx = {letter: idx for idx, letter in enumerate(self.alphabet)}\n",
    "        self.idx_to_letter = {idx: letter for idx, letter in enumerate(self.alphabet)}\n",
    "    \n",
    "    def word_to_sequence(self, word):\n",
    "        \"\"\"Convert word to sequence of letter indices\"\"\"\n",
    "        return [[self.letter_to_idx[letter]] for letter in word.lower() if letter in self.alphabet]\n",
    "    \n",
    "    def train_for_length(self, words_of_length, n_states=5):\n",
    "        \"\"\"Train HMM for words of specific length\"\"\"\n",
    "        if not words_of_length or len(words_of_length) < 2:\n",
    "            return None\n",
    "        \n",
    "        word_length = len(words_of_length[0])\n",
    "        \n",
    "        # Convert words to sequences\n",
    "        sequences = [self.word_to_sequence(word) for word in words_of_length]\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        X = np.concatenate(sequences)\n",
    "        \n",
    "        # Compute letter frequencies for this length\n",
    "        letter_counts = Counter(''.join(words_of_length))\n",
    "        total_letters = sum(letter_counts.values())\n",
    "        freq_vec = np.array([letter_counts.get(ch, 0) / total_letters for ch in self.alphabet])\n",
    "        \n",
    "        # Add smoothing\n",
    "        freq_vec = freq_vec + 1e-6\n",
    "        freq_vec = freq_vec / np.sum(freq_vec)\n",
    "        \n",
    "        # Determine number of states\n",
    "        n_states = min(max(3, word_length // 2), 10)\n",
    "        \n",
    "        # Initialize HMM\n",
    "        model = hmm.MultinomialHMM(n_components=n_states, n_iter=100, random_state=42, tol=0.01)\n",
    "        \n",
    "        model.startprob_ = np.ones(n_states) / n_states\n",
    "        model.transmat_ = np.ones((n_states, n_states)) / n_states\n",
    "        model.emissionprob_ = np.tile(freq_vec, (n_states, 1))\n",
    "        \n",
    "        # Train\n",
    "        try:\n",
    "            model.fit(X, lengths=lengths)\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def train(self, words):\n",
    "        \"\"\"Train separate HMMs for EACH word length\"\"\"\n",
    "        words_by_length = {}\n",
    "        for word in words:\n",
    "            length = len(word)\n",
    "            if length not in words_by_length:\n",
    "                words_by_length[length] = []\n",
    "            words_by_length[length].append(word)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRAINING INDIVIDUAL HMM MODELS FOR EACH WORD LENGTH\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        total_lengths = len(words_by_length)\n",
    "        trained_count = 0\n",
    "        \n",
    "        for i, (length, words_of_length) in enumerate(sorted(words_by_length.items()), 1):\n",
    "            print(f\"[{i:2d}/{total_lengths}] Length {length:2d}: {len(words_of_length):5d} words\", end=\" ... \")\n",
    "            \n",
    "            if len(words_of_length) < 2:\n",
    "                print(\"✗ SKIP (too few)\")\n",
    "                continue\n",
    "            \n",
    "            model = self.train_for_length(words_of_length)\n",
    "            if model is not None:\n",
    "                self.models[length] = model\n",
    "                trained_count += 1\n",
    "                print(\"✓ TRAINED\")\n",
    "            else:\n",
    "                print(\"✗ FAILED\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"Training Summary:\")\n",
    "        print(f\"  - Successfully trained: {trained_count}/{total_lengths}\")\n",
    "        print(f\"  - Covered word lengths: {sorted(self.models.keys())}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return self.models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6dd0fe",
   "metadata": {},
   "source": [
    "## Step 3: HMM Model Class\n",
    "\n",
    "**Algorithm:** Hidden Markov Model (Baum-Welch Training)\n",
    "- Separate models for each word length\n",
    "- Letter frequency-based initialization\n",
    "- Laplace smoothing for probability estimation\n",
    "- Emission probabilities capture letter patterns\n",
    "- MultinomialHMM with 3-10 states depending on word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cadec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Some rows of transmat_ have zero sum because no transition from the state was ever observed.\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models...\n",
      "\n",
      "======================================================================\n",
      "TRAINING INDIVIDUAL HMM MODELS FOR EACH WORD LENGTH\n",
      "======================================================================\n",
      "[ 1/24] Length  1:    46 words ... ✓ TRAINED\n",
      "[ 2/24] Length  2:    84 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 3/24] Length  3:   388 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 4/24] Length  4:  1169 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 5/24] Length  5:  2340 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 6/24] Length  6:  3755 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 7/24] Length  7:  5111 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 8/24] Length  8:  6348 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[ 9/24] Length  9:  6787 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[10/24] Length 10:  6465 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[11/24] Length 11:  5452 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[12/24] Length 12:  4292 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[13/24] Length 13:  3094 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[14/24] Length 14:  2019 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[15/24] Length 15:  1226 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[16/24] Length 16:   698 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[17/24] Length 17:   375 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[18/24] Length 18:   174 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[19/24] Length 19:    88 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[20/24] Length 20:    40 words ... ✓ TRAINED\n",
      "[21/24] Length 21:    16 words ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Fitting a model with 99 free scalar parameters with only 69 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TRAINED\n",
      "[22/24] Length 22:     8 words ... ✓ TRAINED\n",
      "[23/24] Length 23:     3 words ... ✓ TRAINED\n",
      "[24/24] Length 24:     1 words ... ✗ SKIP (too few)\n",
      "\n",
      "======================================================================\n",
      "Training Summary:\n",
      "  - Successfully trained: 23/24\n",
      "  - Covered word lengths: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "SAVING MODELS\n",
      "======================================================================\n",
      "Saved 23 trained models\n",
      "Model file: 'hmm_hangman_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PREDICTION CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class HangmanPredictor:\n",
    "    \"\"\"Predict next letter using trained HMM\"\"\"\n",
    "    \n",
    "    def __init__(self, hmm_model):\n",
    "        self.hmm_model = hmm_model\n",
    "        self.alphabet = string.ascii_lowercase\n",
    "        self.letter_to_idx = {letter: idx for idx, letter in enumerate(self.alphabet)}\n",
    "        self.idx_to_letter = {idx: letter for idx, letter in enumerate(self.alphabet)}\n",
    "    \n",
    "    def get_letter_probabilities(self, word_length):\n",
    "        \"\"\"Compute letter probabilities for each position\"\"\"\n",
    "        if word_length not in self.hmm_model.models:\n",
    "            return np.ones((26, word_length)) / 26\n",
    "        \n",
    "        model = self.hmm_model.models[word_length]\n",
    "        \n",
    "        try:\n",
    "            emission_probs = model.emissionprob_\n",
    "            avg_emission = np.mean(emission_probs, axis=0)\n",
    "            \n",
    "            avg_emission = np.maximum(avg_emission, 1e-10)\n",
    "            emission_probs_normalized = avg_emission / np.sum(avg_emission)\n",
    "            \n",
    "            position_probs = np.tile(emission_probs_normalized, (word_length, 1)).T\n",
    "            return position_probs\n",
    "        except Exception as e:\n",
    "            return np.ones((26, word_length)) / 26\n",
    "    \n",
    "    def predict_next_letter(self, masked_word, guessed_letters):\n",
    "        \"\"\"Predict next best letter to guess\"\"\"\n",
    "        word_length = len(masked_word)\n",
    "        \n",
    "        probs = self.get_letter_probabilities(word_length)\n",
    "        \n",
    "        if probs.shape[0] != 26 or probs.shape[1] != word_length:\n",
    "            probs = np.ones((26, word_length)) / 26\n",
    "        \n",
    "        unknown_positions = [i for i, c in enumerate(masked_word) if c == '_']\n",
    "        if unknown_positions:\n",
    "            avg_probs = np.mean(probs[:, unknown_positions], axis=1)\n",
    "        else:\n",
    "            avg_probs = np.mean(probs, axis=1)\n",
    "        \n",
    "        if len(avg_probs) != 26:\n",
    "            avg_probs = np.ones(26) / 26\n",
    "        \n",
    "        for letter in guessed_letters:\n",
    "            if letter in self.letter_to_idx:\n",
    "                idx = self.letter_to_idx[letter]\n",
    "                avg_probs[idx] = 0\n",
    "        \n",
    "        total_prob = np.sum(avg_probs)\n",
    "        if total_prob > 1e-10:\n",
    "            avg_probs = avg_probs / total_prob\n",
    "        else:\n",
    "            avg_probs = np.ones(26) / 26\n",
    "        \n",
    "        best_idx = np.argmax(avg_probs)\n",
    "        best_letter = self.alphabet[best_idx]\n",
    "        best_prob = avg_probs[best_idx]\n",
    "        \n",
    "        return best_letter, best_prob\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN AND SAVE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nTraining models...\")\n",
    "hmm_model = HangmanHMM()\n",
    "hmm_model.train(processed_words)\n",
    "\n",
    "predictor = HangmanPredictor(hmm_model)\n",
    "\n",
    "# Save models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_data = {\n",
    "    'hmm_model': hmm_model,\n",
    "    'predictor': predictor,\n",
    "    'trained_lengths': list(hmm_model.models.keys())\n",
    "}\n",
    "\n",
    "with open('hmm_hangman_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(f\"Saved {len(hmm_model.models)} trained models\")\n",
    "print(f\"Model file: 'hmm_hangman_model.pkl'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe59d9",
   "metadata": {},
   "source": [
    "## Step 4: Prediction Engine & Model Training\n",
    "\n",
    "**Algorithm:** Letter Probability Inference + Model Persistence\n",
    "- Extract emission probabilities from trained HMM\n",
    "- Predict best letter using argmax on probability distribution\n",
    "- Exclude already-guessed letters\n",
    "- Save serialized models using pickle for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2add4cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDATING MODEL ON TEST DATA\n",
      "======================================================================\n",
      "\n",
      "Running predictions on test set...\n",
      "  Progress: 2000/2000 ✓\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VALIDATION AND SUCCESS RATE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATING MODEL ON TEST DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def simulate_hangman_game(word, hmm_model, predictor, num_reveals=1):\n",
    "    \"\"\"Simulate Hangman game and check prediction accuracy\"\"\"\n",
    "    if len(word) < 3:\n",
    "        return None\n",
    "    \n",
    "    word = word.lower()\n",
    "    masked = ['_'] * len(word)\n",
    "    guessed_letters = set()\n",
    "    \n",
    "    # Randomly reveal initial letters\n",
    "    reveal_indices = np.random.choice(len(word), min(num_reveals, len(word)), replace=False)\n",
    "    for idx in reveal_indices:\n",
    "        masked[idx] = word[idx]\n",
    "        guessed_letters.add(word[idx])\n",
    "    \n",
    "    masked_word = ''.join(masked)\n",
    "    \n",
    "    try:\n",
    "        next_letter, probability = predictor.predict_next_letter(masked_word, guessed_letters)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    # Check if prediction is correct\n",
    "    remaining_letters = set(c for i, c in enumerate(word) \n",
    "                           if c not in guessed_letters and masked[i] == '_')\n",
    "    is_correct = next_letter in remaining_letters\n",
    "    \n",
    "    return {\n",
    "        'word': word,\n",
    "        'masked_word': masked_word,\n",
    "        'prediction': next_letter,\n",
    "        'probability': probability,\n",
    "        'is_correct': is_correct,\n",
    "        'word_length': len(word),\n",
    "        'has_model': len(word) in hmm_model.models\n",
    "    }\n",
    "\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "\n",
    "print(\"\\nRunning predictions on test set...\")\n",
    "for i, word in enumerate(test_words):\n",
    "    if i % 500 == 0:\n",
    "        print(f\"  Progress: {i}/{len(test_words)}\", end='\\r')\n",
    "    \n",
    "    result = simulate_hangman_game(word, hmm_model, predictor, num_reveals=1)\n",
    "    if result is not None:\n",
    "        results.append(result)\n",
    "\n",
    "print(f\"  Progress: {len(test_words)}/{len(test_words)} ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efc9f2",
   "metadata": {},
   "source": [
    "## Step 5: Model Validation & Testing\n",
    "\n",
    "**Algorithm:**  Accuracy Testing\n",
    "- Simulate Hangman games with random letter reveals\n",
    "- Use trained HMM predictor for letter guessing\n",
    "- Calculate correctness of predictions\n",
    "- Stratified analysis by word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c6ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUCCESS RATE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "OVERALL SUCCESS RATE.............................. 54.95%\n",
      "Total Predictions................................. 1998\n",
      "Correct Predictions............................... 1098\n",
      "Incorrect Predictions............................. 900\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SUCCESS RATE BY WORD LENGTH\n",
      "----------------------------------------------------------------------\n",
      "Length  3 ✓:  44.44% (  4/  9)\n",
      "Length  4 ✓:  43.24% ( 16/ 37)\n",
      "Length  5 ✓:  40.66% ( 37/ 91)\n",
      "Length  6 ✓:  40.58% ( 56/138)\n",
      "Length  7 ✓:  46.83% ( 96/205)\n",
      "Length  8 ✓:  49.19% (121/246)\n",
      "Length  9 ✓:  51.09% (140/274)\n",
      "Length 10 ✓:  56.38% (159/282)\n",
      "Length 11 ✓:  54.87% (124/226)\n",
      "Length 12 ✓:  64.63% (106/164)\n",
      "Length 13 ✓:  68.75% ( 88/128)\n",
      "Length 14 ✓:  73.26% ( 63/ 86)\n",
      "Length 15 ✓:  70.21% ( 33/ 47)\n",
      "Length 16 ✓:  87.88% ( 29/ 33)\n",
      "Length 17 ✓:  64.71% ( 11/ 17)\n",
      "Length 18 ✓: 100.00% (  8/  8)\n",
      "Length 19 ✓: 100.00% (  3/  3)\n",
      "Length 20 ✓: 100.00% (  2/  2)\n",
      "Length 21 ✓: 100.00% (  1/  1)\n",
      "Length 22 ✓: 100.00% (  1/  1)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PREDICTION CONFIDENCE METRICS\n",
      "----------------------------------------------------------------------\n",
      "Avg Confidence (Correct).......................... 0.0400\n",
      "Avg Confidence (Incorrect)........................ 0.0400\n",
      "Confidence Gap.................................... -0.0000\n",
      "Overall Avg Confidence............................ 0.0400\n",
      "\n",
      "✓ Results saved to 'hmm_validation_results.json'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CALCULATE SUCCESS METRICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUCCESS RATE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "correct = sum(1 for r in results if r['is_correct'])\n",
    "total = len(results)\n",
    "success_rate = (correct / total) * 100 if total > 0 else 0\n",
    "\n",
    "print(f\"\\n{'OVERALL SUCCESS RATE':.<50} {success_rate:.2f}%\")\n",
    "print(f\"{'Total Predictions':.<50} {total}\")\n",
    "print(f\"{'Correct Predictions':.<50} {correct}\")\n",
    "print(f\"{'Incorrect Predictions':.<50} {total - correct}\")\n",
    "\n",
    "# Success rate by word length\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"SUCCESS RATE BY WORD LENGTH\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "success_by_length = {}\n",
    "for r in results:\n",
    "    length = r['word_length']\n",
    "    if length not in success_by_length:\n",
    "        success_by_length[length] = {'correct': 0, 'total': 0, 'with_model': 0}\n",
    "    success_by_length[length]['total'] += 1\n",
    "    if r['has_model']:\n",
    "        success_by_length[length]['with_model'] += 1\n",
    "    if r['is_correct']:\n",
    "        success_by_length[length]['correct'] += 1\n",
    "\n",
    "for length in sorted(success_by_length.keys()):\n",
    "    data = success_by_length[length]\n",
    "    rate = (data['correct'] / data['total'] * 100) if data['total'] > 0 else 0\n",
    "    model_status = \"✓\" if data['with_model'] > 0 else \"✗\"\n",
    "    print(f\"Length {length:2d} {model_status}: {rate:6.2f}% ({data['correct']:3d}/{data['total']:3d})\")\n",
    "\n",
    "# Confidence analysis\n",
    "correct_probs = [r['probability'] for r in results if r['is_correct']]\n",
    "incorrect_probs = [r['probability'] for r in results if not r['is_correct']]\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"PREDICTION CONFIDENCE METRICS\")\n",
    "print(\"-\"*70)\n",
    "if len(correct_probs) > 0:\n",
    "    print(f\"{'Avg Confidence (Correct)':.<50} {np.mean(correct_probs):.4f}\")\n",
    "if len(incorrect_probs) > 0:\n",
    "    print(f\"{'Avg Confidence (Incorrect)':.<50} {np.mean(incorrect_probs):.4f}\")\n",
    "if len(correct_probs) > 0 and len(incorrect_probs) > 0:\n",
    "    print(f\"{'Confidence Gap':.<50} {np.mean(correct_probs) - np.mean(incorrect_probs):.4f}\")\n",
    "\n",
    "print(f\"{'Overall Avg Confidence':.<50} {np.mean([r['probability'] for r in results]):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "results_summary = {\n",
    "    'overall_success_rate': success_rate,\n",
    "    'total_predictions': total,\n",
    "    'correct_predictions': correct,\n",
    "    'incorrect_predictions': total - correct,\n",
    "    'by_word_length': {},\n",
    "    'trained_lengths': list(hmm_model.models.keys()),\n",
    "    'total_trained_models': len(hmm_model.models)\n",
    "}\n",
    "\n",
    "for length in sorted(success_by_length.keys()):\n",
    "    data = success_by_length[length]\n",
    "    rate = (data['correct'] / data['total'] * 100) if data['total'] > 0 else 0\n",
    "    results_summary['by_word_length'][str(length)] = {\n",
    "        'success_rate': rate,\n",
    "        'correct': data['correct'],\n",
    "        'total': data['total'],\n",
    "        'has_model': data['with_model'] > 0\n",
    "    }\n",
    "\n",
    "# Save results to JSON\n",
    "with open('hmm_validation_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=4)\n",
    "\n",
    "print(\"\\n✓ Results saved to 'hmm_validation_results.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488894de",
   "metadata": {},
   "source": [
    "## Step 6: Performance Metrics & Analysis\n",
    "\n",
    "**Algorithms:** Descriptive Statistics + Confidence Analysis\n",
    "- Compute success rates (overall and by word length)\n",
    "- Analyze prediction confidence distributions\n",
    "- Calculate confidence gap between correct/incorrect predictions\n",
    "- Serialize results to JSON for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ecf317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
